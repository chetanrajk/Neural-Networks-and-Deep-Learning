{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Chetan\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import backend as k\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\").astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "#Keras sequential models for different implementations\n",
    "model = Sequential()\n",
    "model1 = Sequential()\n",
    "model2 = Sequential()\n",
    "model3 = Sequential()\n",
    "model4 = Sequential()\n",
    "model5 = Sequential()\n",
    "model6 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the data as training data = 80% and testing data = 20%\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "614/614 [==============================] - 2s 4ms/step - loss: 0.3223 - acc: 0.6189\n",
      "Epoch 2/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2329 - acc: 0.6352\n",
      "Epoch 3/150\n",
      "614/614 [==============================] - 0s 109us/step - loss: 0.2229 - acc: 0.6368\n",
      "Epoch 4/150\n",
      "614/614 [==============================] - 0s 97us/step - loss: 0.2242 - acc: 0.6352\n",
      "Epoch 5/150\n",
      "614/614 [==============================] - 0s 101us/step - loss: 0.2213 - acc: 0.6368\n",
      "Epoch 6/150\n",
      "614/614 [==============================] - 0s 83us/step - loss: 0.2214 - acc: 0.6368\n",
      "Epoch 7/150\n",
      "614/614 [==============================] - 0s 78us/step - loss: 0.2193 - acc: 0.6368\n",
      "Epoch 8/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.2181 - acc: 0.6384\n",
      "Epoch 9/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.2210 - acc: 0.6156\n",
      "Epoch 10/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.2181 - acc: 0.6368\n",
      "Epoch 11/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.2188 - acc: 0.6384\n",
      "Epoch 12/150\n",
      "614/614 [==============================] - 0s 78us/step - loss: 0.2179 - acc: 0.6368\n",
      "Epoch 13/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.2155 - acc: 0.6352\n",
      "Epoch 14/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.2156 - acc: 0.6384\n",
      "Epoch 15/150\n",
      "614/614 [==============================] - 0s 78us/step - loss: 0.2129 - acc: 0.6368\n",
      "Epoch 16/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.2146 - acc: 0.6287\n",
      "Epoch 17/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.2116 - acc: 0.6417\n",
      "Epoch 18/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.2159 - acc: 0.6303\n",
      "Epoch 19/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.2104 - acc: 0.6417\n",
      "Epoch 20/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.2096 - acc: 0.6384\n",
      "Epoch 21/150\n",
      "614/614 [==============================] - 0s 80us/step - loss: 0.2120 - acc: 0.6401\n",
      "Epoch 22/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2109 - acc: 0.6417\n",
      "Epoch 23/150\n",
      "614/614 [==============================] - 0s 107us/step - loss: 0.2087 - acc: 0.6352\n",
      "Epoch 24/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2062 - acc: 0.6401\n",
      "Epoch 25/150\n",
      "614/614 [==============================] - 0s 96us/step - loss: 0.2118 - acc: 0.6173\n",
      "Epoch 26/150\n",
      "614/614 [==============================] - 0s 99us/step - loss: 0.2066 - acc: 0.6466\n",
      "Epoch 27/150\n",
      "614/614 [==============================] - 0s 93us/step - loss: 0.2055 - acc: 0.6336\n",
      "Epoch 28/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.2054 - acc: 0.6531\n",
      "Epoch 29/150\n",
      "614/614 [==============================] - 0s 81us/step - loss: 0.2071 - acc: 0.6515\n",
      "Epoch 30/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.2026 - acc: 0.6678\n",
      "Epoch 31/150\n",
      "614/614 [==============================] - 0s 97us/step - loss: 0.2067 - acc: 0.6661\n",
      "Epoch 32/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2036 - acc: 0.6661\n",
      "Epoch 33/150\n",
      "614/614 [==============================] - 0s 110us/step - loss: 0.2017 - acc: 0.6629\n",
      "Epoch 34/150\n",
      "614/614 [==============================] - 0s 101us/step - loss: 0.2070 - acc: 0.6515\n",
      "Epoch 35/150\n",
      "614/614 [==============================] - 0s 94us/step - loss: 0.2051 - acc: 0.6629\n",
      "Epoch 36/150\n",
      "614/614 [==============================] - 0s 97us/step - loss: 0.2041 - acc: 0.6612\n",
      "Epoch 37/150\n",
      "614/614 [==============================] - 0s 81us/step - loss: 0.2015 - acc: 0.6824\n",
      "Epoch 38/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.2007 - acc: 0.6629\n",
      "Epoch 39/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.2001 - acc: 0.6808\n",
      "Epoch 40/150\n",
      "614/614 [==============================] - 0s 81us/step - loss: 0.2022 - acc: 0.6840\n",
      "Epoch 41/150\n",
      "614/614 [==============================] - 0s 78us/step - loss: 0.1982 - acc: 0.6971\n",
      "Epoch 42/150\n",
      "614/614 [==============================] - 0s 107us/step - loss: 0.2022 - acc: 0.6661\n",
      "Epoch 43/150\n",
      "614/614 [==============================] - 0s 107us/step - loss: 0.1981 - acc: 0.7068\n",
      "Epoch 44/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.1990 - acc: 0.6857\n",
      "Epoch 45/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.1972 - acc: 0.6857\n",
      "Epoch 46/150\n",
      "614/614 [==============================] - 0s 97us/step - loss: 0.2009 - acc: 0.6889\n",
      "Epoch 47/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1998 - acc: 0.6840\n",
      "Epoch 48/150\n",
      "614/614 [==============================] - 0s 78us/step - loss: 0.1990 - acc: 0.6938\n",
      "Epoch 49/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.2009 - acc: 0.6775\n",
      "Epoch 50/150\n",
      "614/614 [==============================] - 0s 78us/step - loss: 0.1955 - acc: 0.6873\n",
      "Epoch 51/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1969 - acc: 0.6954\n",
      "Epoch 52/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.1969 - acc: 0.6889\n",
      "Epoch 53/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.1959 - acc: 0.6971\n",
      "Epoch 54/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.1977 - acc: 0.6906\n",
      "Epoch 55/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1951 - acc: 0.6873\n",
      "Epoch 56/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1958 - acc: 0.6857\n",
      "Epoch 57/150\n",
      "614/614 [==============================] - 0s 80us/step - loss: 0.1993 - acc: 0.6645\n",
      "Epoch 58/150\n",
      "614/614 [==============================] - 0s 81us/step - loss: 0.1955 - acc: 0.6775\n",
      "Epoch 59/150\n",
      "614/614 [==============================] - 0s 81us/step - loss: 0.1957 - acc: 0.6873\n",
      "Epoch 60/150\n",
      "614/614 [==============================] - 0s 101us/step - loss: 0.1940 - acc: 0.6971\n",
      "Epoch 61/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.1968 - acc: 0.6889\n",
      "Epoch 62/150\n",
      "614/614 [==============================] - 0s 107us/step - loss: 0.1946 - acc: 0.6954\n",
      "Epoch 63/150\n",
      "614/614 [==============================] - 0s 101us/step - loss: 0.1971 - acc: 0.6775\n",
      "Epoch 64/150\n",
      "614/614 [==============================] - 0s 78us/step - loss: 0.1947 - acc: 0.6906\n",
      "Epoch 65/150\n",
      "614/614 [==============================] - 0s 80us/step - loss: 0.1929 - acc: 0.6889\n",
      "Epoch 66/150\n",
      "614/614 [==============================] - 0s 89us/step - loss: 0.2018 - acc: 0.6645\n",
      "Epoch 67/150\n",
      "614/614 [==============================] - 0s 84us/step - loss: 0.1948 - acc: 0.6938\n",
      "Epoch 68/150\n",
      "614/614 [==============================] - 0s 107us/step - loss: 0.1943 - acc: 0.6938\n",
      "Epoch 69/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.1930 - acc: 0.6922\n",
      "Epoch 70/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.1944 - acc: 0.6792\n",
      "Epoch 71/150\n",
      "614/614 [==============================] - 0s 97us/step - loss: 0.1930 - acc: 0.6840\n",
      "Epoch 72/150\n",
      "614/614 [==============================] - 0s 83us/step - loss: 0.1964 - acc: 0.6873\n",
      "Epoch 73/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1973 - acc: 0.6971\n",
      "Epoch 74/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1932 - acc: 0.6938\n",
      "Epoch 75/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1938 - acc: 0.6987\n",
      "Epoch 76/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1930 - acc: 0.7036\n",
      "Epoch 77/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.1931 - acc: 0.6840\n",
      "Epoch 78/150\n",
      "614/614 [==============================] - 0s 83us/step - loss: 0.1934 - acc: 0.6873\n",
      "Epoch 79/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1966 - acc: 0.7003\n",
      "Epoch 80/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1975 - acc: 0.6661\n",
      "Epoch 81/150\n",
      "614/614 [==============================] - 0s 80us/step - loss: 0.1925 - acc: 0.6938\n",
      "Epoch 82/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.1917 - acc: 0.7003\n",
      "Epoch 83/150\n",
      "614/614 [==============================] - 0s 84us/step - loss: 0.1924 - acc: 0.6954\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 104us/step - loss: 0.1909 - acc: 0.6971\n",
      "Epoch 85/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.1930 - acc: 0.6922\n",
      "Epoch 86/150\n",
      "614/614 [==============================] - 0s 101us/step - loss: 0.1927 - acc: 0.6954\n",
      "Epoch 87/150\n",
      "614/614 [==============================] - 0s 99us/step - loss: 0.1961 - acc: 0.6840\n",
      "Epoch 88/150\n",
      "614/614 [==============================] - 0s 96us/step - loss: 0.1930 - acc: 0.6873\n",
      "Epoch 89/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.1882 - acc: 0.7085\n",
      "Epoch 90/150\n",
      "614/614 [==============================] - 0s 80us/step - loss: 0.1903 - acc: 0.6857\n",
      "Epoch 91/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.1939 - acc: 0.6824\n",
      "Epoch 92/150\n",
      "614/614 [==============================] - 0s 78us/step - loss: 0.1903 - acc: 0.7117\n",
      "Epoch 93/150\n",
      "614/614 [==============================] - 0s 97us/step - loss: 0.1921 - acc: 0.6954\n",
      "Epoch 94/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.1895 - acc: 0.7150\n",
      "Epoch 95/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.1866 - acc: 0.7280\n",
      "Epoch 96/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.1875 - acc: 0.7052\n",
      "Epoch 97/150\n",
      "614/614 [==============================] - 0s 94us/step - loss: 0.1877 - acc: 0.7134\n",
      "Epoch 98/150\n",
      "614/614 [==============================] - 0s 84us/step - loss: 0.1900 - acc: 0.6971\n",
      "Epoch 99/150\n",
      "614/614 [==============================] - 0s 80us/step - loss: 0.1872 - acc: 0.6954\n",
      "Epoch 100/150\n",
      "614/614 [==============================] - 0s 84us/step - loss: 0.1869 - acc: 0.7003\n",
      "Epoch 101/150\n",
      "614/614 [==============================] - 0s 91us/step - loss: 0.1898 - acc: 0.6938\n",
      "Epoch 102/150\n",
      "614/614 [==============================] - 0s 109us/step - loss: 0.1869 - acc: 0.7182\n",
      "Epoch 103/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.1925 - acc: 0.7052\n",
      "Epoch 104/150\n",
      "614/614 [==============================] - 0s 99us/step - loss: 0.1894 - acc: 0.7280\n",
      "Epoch 105/150\n",
      "614/614 [==============================] - 0s 94us/step - loss: 0.1892 - acc: 0.7134\n",
      "Epoch 106/150\n",
      "614/614 [==============================] - 0s 97us/step - loss: 0.1896 - acc: 0.7068\n",
      "Epoch 107/150\n",
      "614/614 [==============================] - 0s 78us/step - loss: 0.1880 - acc: 0.7020\n",
      "Epoch 108/150\n",
      "614/614 [==============================] - 0s 81us/step - loss: 0.1855 - acc: 0.7182\n",
      "Epoch 109/150\n",
      "614/614 [==============================] - 0s 93us/step - loss: 0.1903 - acc: 0.7117\n",
      "Epoch 110/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.1856 - acc: 0.7182\n",
      "Epoch 111/150\n",
      "614/614 [==============================] - 0s 101us/step - loss: 0.1875 - acc: 0.7134\n",
      "Epoch 112/150\n",
      "614/614 [==============================] - 0s 88us/step - loss: 0.1875 - acc: 0.7117\n",
      "Epoch 113/150\n",
      "614/614 [==============================] - 0s 81us/step - loss: 0.1884 - acc: 0.7150\n",
      "Epoch 114/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1879 - acc: 0.7134\n",
      "Epoch 115/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1836 - acc: 0.7215\n",
      "Epoch 116/150\n",
      "614/614 [==============================] - 0s 71us/step - loss: 0.1935 - acc: 0.7036\n",
      "Epoch 117/150\n",
      "614/614 [==============================] - 0s 71us/step - loss: 0.1846 - acc: 0.7166\n",
      "Epoch 118/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1885 - acc: 0.7166\n",
      "Epoch 119/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1865 - acc: 0.7085\n",
      "Epoch 120/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1848 - acc: 0.7052\n",
      "Epoch 121/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1855 - acc: 0.7052\n",
      "Epoch 122/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1864 - acc: 0.7117\n",
      "Epoch 123/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1851 - acc: 0.7166\n",
      "Epoch 124/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1853 - acc: 0.7036\n",
      "Epoch 125/150\n",
      "614/614 [==============================] - 0s 71us/step - loss: 0.1855 - acc: 0.7052\n",
      "Epoch 126/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1850 - acc: 0.7150\n",
      "Epoch 127/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1889 - acc: 0.6987\n",
      "Epoch 128/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1867 - acc: 0.7150\n",
      "Epoch 129/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1870 - acc: 0.7182\n",
      "Epoch 130/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1847 - acc: 0.7166\n",
      "Epoch 131/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1911 - acc: 0.6971\n",
      "Epoch 132/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1872 - acc: 0.7052\n",
      "Epoch 133/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1854 - acc: 0.7199\n",
      "Epoch 134/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.1829 - acc: 0.7248\n",
      "Epoch 135/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1915 - acc: 0.7166\n",
      "Epoch 136/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.1899 - acc: 0.7134\n",
      "Epoch 137/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1890 - acc: 0.7101\n",
      "Epoch 138/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1862 - acc: 0.7199\n",
      "Epoch 139/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1903 - acc: 0.7020\n",
      "Epoch 140/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1830 - acc: 0.7231\n",
      "Epoch 141/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1848 - acc: 0.7231\n",
      "Epoch 142/150\n",
      "614/614 [==============================] - 0s 75us/step - loss: 0.1809 - acc: 0.7313\n",
      "Epoch 143/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.1838 - acc: 0.7248\n",
      "Epoch 144/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1828 - acc: 0.7215\n",
      "Epoch 145/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1808 - acc: 0.7182\n",
      "Epoch 146/150\n",
      "614/614 [==============================] - 0s 73us/step - loss: 0.1818 - acc: 0.7199\n",
      "Epoch 147/150\n",
      "614/614 [==============================] - 0s 76us/step - loss: 0.1842 - acc: 0.7215\n",
      "Epoch 148/150\n",
      "614/614 [==============================] - 0s 71us/step - loss: 0.1855 - acc: 0.7329\n",
      "Epoch 149/150\n",
      "614/614 [==============================] - 0s 78us/step - loss: 0.1841 - acc: 0.7199\n",
      "Epoch 150/150\n",
      "614/614 [==============================] - 0s 86us/step - loss: 0.1827 - acc: 0.6938\n",
      "154/154 [==============================] - 0s 194us/step\n",
      "\n",
      "acc: 69.48%\n"
     ]
    }
   ],
   "source": [
    "#Neural network model using sigmoid activation function\n",
    "model.add(Dense(8, input_dim=8))\n",
    "model.add(Dense(16,activation = \"sigmoid\"))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, epochs=150, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 0.4110 - acc: 0.5489\n",
      "Epoch 2/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.2572 - acc: 0.6156\n",
      "Epoch 3/150\n",
      "614/614 [==============================] - 0s 110us/step - loss: 0.2343 - acc: 0.6270\n",
      "Epoch 4/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2257 - acc: 0.6368\n",
      "Epoch 5/150\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.2264 - acc: 0.6417\n",
      "Epoch 6/150\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.2264 - acc: 0.6466\n",
      "Epoch 7/150\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.2254 - acc: 0.6254\n",
      "Epoch 8/150\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.2260 - acc: 0.6124\n",
      "Epoch 9/150\n",
      "614/614 [==============================] - 0s 107us/step - loss: 0.2251 - acc: 0.6287\n",
      "Epoch 10/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.2216 - acc: 0.6303\n",
      "Epoch 11/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.2245 - acc: 0.6352\n",
      "Epoch 12/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2234 - acc: 0.6205\n",
      "Epoch 13/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2261 - acc: 0.6270\n",
      "Epoch 14/150\n",
      "614/614 [==============================] - 0s 107us/step - loss: 0.2233 - acc: 0.6156\n",
      "Epoch 15/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.2245 - acc: 0.6221\n",
      "Epoch 16/150\n",
      "614/614 [==============================] - 0s 110us/step - loss: 0.2248 - acc: 0.6254\n",
      "Epoch 17/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.2223 - acc: 0.6303\n",
      "Epoch 18/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.2241 - acc: 0.6238\n",
      "Epoch 19/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2239 - acc: 0.6221\n",
      "Epoch 20/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.2232 - acc: 0.6205\n",
      "Epoch 21/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2228 - acc: 0.6205\n",
      "Epoch 22/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2241 - acc: 0.6270\n",
      "Epoch 23/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2234 - acc: 0.6384\n",
      "Epoch 24/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2208 - acc: 0.6433\n",
      "Epoch 25/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2212 - acc: 0.6368\n",
      "Epoch 26/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.2223 - acc: 0.6450\n",
      "Epoch 27/150\n",
      "614/614 [==============================] - 0s 101us/step - loss: 0.2188 - acc: 0.6498\n",
      "Epoch 28/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2222 - acc: 0.6433\n",
      "Epoch 29/150\n",
      "614/614 [==============================] - 0s 101us/step - loss: 0.2219 - acc: 0.6303\n",
      "Epoch 30/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2208 - acc: 0.6433\n",
      "Epoch 31/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.2168 - acc: 0.6482\n",
      "Epoch 32/150\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.2226 - acc: 0.6319\n",
      "Epoch 33/150\n",
      "614/614 [==============================] - 0s 109us/step - loss: 0.2223 - acc: 0.6417\n",
      "Epoch 34/150\n",
      "614/614 [==============================] - 0s 112us/step - loss: 0.2178 - acc: 0.6466\n",
      "Epoch 35/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2197 - acc: 0.6498\n",
      "Epoch 36/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2191 - acc: 0.6498\n",
      "Epoch 37/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2190 - acc: 0.6221\n",
      "Epoch 38/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2225 - acc: 0.6173\n",
      "Epoch 39/150\n",
      "614/614 [==============================] - 0s 109us/step - loss: 0.2172 - acc: 0.6401\n",
      "Epoch 40/150\n",
      "614/614 [==============================] - 0s 112us/step - loss: 0.2196 - acc: 0.6401\n",
      "Epoch 41/150\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.2201 - acc: 0.6238\n",
      "Epoch 42/150\n",
      "614/614 [==============================] - 0s 110us/step - loss: 0.2158 - acc: 0.6450\n",
      "Epoch 43/150\n",
      "614/614 [==============================] - 0s 110us/step - loss: 0.2181 - acc: 0.6336\n",
      "Epoch 44/150\n",
      "614/614 [==============================] - 0s 110us/step - loss: 0.2172 - acc: 0.6515\n",
      "Epoch 45/150\n",
      "614/614 [==============================] - 0s 109us/step - loss: 0.2176 - acc: 0.6384\n",
      "Epoch 46/150\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.2171 - acc: 0.6433\n",
      "Epoch 47/150\n",
      "614/614 [==============================] - 0s 101us/step - loss: 0.2183 - acc: 0.6433\n",
      "Epoch 48/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2129 - acc: 0.6482\n",
      "Epoch 49/150\n",
      "614/614 [==============================] - 0s 101us/step - loss: 0.2168 - acc: 0.6352\n",
      "Epoch 50/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2148 - acc: 0.6580\n",
      "Epoch 51/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2122 - acc: 0.6580\n",
      "Epoch 52/150\n",
      "614/614 [==============================] - 0s 112us/step - loss: 0.2159 - acc: 0.6482\n",
      "Epoch 53/150\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.2189 - acc: 0.6433\n",
      "Epoch 54/150\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.2124 - acc: 0.6645\n",
      "Epoch 55/150\n",
      "614/614 [==============================] - 0s 109us/step - loss: 0.2177 - acc: 0.6433\n",
      "Epoch 56/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2141 - acc: 0.6564\n",
      "Epoch 57/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2142 - acc: 0.6287\n",
      "Epoch 58/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2162 - acc: 0.6336\n",
      "Epoch 59/150\n",
      "614/614 [==============================] - 0s 109us/step - loss: 0.2094 - acc: 0.6612\n",
      "Epoch 60/150\n",
      "614/614 [==============================] - 0s 107us/step - loss: 0.2190 - acc: 0.6368\n",
      "Epoch 61/150\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.2152 - acc: 0.6417\n",
      "Epoch 62/150\n",
      "614/614 [==============================] - 0s 107us/step - loss: 0.2128 - acc: 0.6466\n",
      "Epoch 63/150\n",
      "614/614 [==============================] - 0s 107us/step - loss: 0.2138 - acc: 0.6482\n",
      "Epoch 64/150\n",
      "614/614 [==============================] - 0s 109us/step - loss: 0.2137 - acc: 0.6515\n",
      "Epoch 65/150\n",
      "614/614 [==============================] - 0s 112us/step - loss: 0.2088 - acc: 0.6792\n",
      "Epoch 66/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2091 - acc: 0.6645\n",
      "Epoch 67/150\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.2089 - acc: 0.6629\n",
      "Epoch 68/150\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.2060 - acc: 0.6564\n",
      "Epoch 69/150\n",
      "614/614 [==============================] - 0s 112us/step - loss: 0.2090 - acc: 0.6596\n",
      "Epoch 70/150\n",
      "614/614 [==============================] - 0s 107us/step - loss: 0.2133 - acc: 0.6596\n",
      "Epoch 71/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2097 - acc: 0.6564\n",
      "Epoch 72/150\n",
      "614/614 [==============================] - 0s 101us/step - loss: 0.2073 - acc: 0.6759\n",
      "Epoch 73/150\n",
      "614/614 [==============================] - 0s 101us/step - loss: 0.2113 - acc: 0.6498\n",
      "Epoch 74/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2105 - acc: 0.6580\n",
      "Epoch 75/150\n",
      "614/614 [==============================] - 0s 102us/step - loss: 0.2066 - acc: 0.6482\n",
      "Epoch 76/150\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.2067 - acc: 0.6661\n",
      "Epoch 77/150\n",
      "614/614 [==============================] - 0s 112us/step - loss: 0.2066 - acc: 0.6678\n",
      "Epoch 78/150\n",
      "614/614 [==============================] - 0s 140us/step - loss: 0.2056 - acc: 0.6612\n",
      "Epoch 79/150\n",
      "614/614 [==============================] - 0s 138us/step - loss: 0.2070 - acc: 0.6629\n",
      "Epoch 80/150\n",
      "614/614 [==============================] - 0s 123us/step - loss: 0.2027 - acc: 0.6694\n",
      "Epoch 81/150\n",
      "614/614 [==============================] - 0s 128us/step - loss: 0.2088 - acc: 0.6531\n",
      "Epoch 82/150\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.2035 - acc: 0.6759\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 117us/step - loss: 0.2074 - acc: 0.6759\n",
      "Epoch 84/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.2109 - acc: 0.6612\n",
      "Epoch 85/150\n",
      "614/614 [==============================] - 0s 143us/step - loss: 0.2075 - acc: 0.6629\n",
      "Epoch 86/150\n",
      "614/614 [==============================] - 0s 153us/step - loss: 0.2072 - acc: 0.6580\n",
      "Epoch 87/150\n",
      "614/614 [==============================] - 0s 146us/step - loss: 0.2052 - acc: 0.6857 0s - loss: 0.2187 - acc: 0.660\n",
      "Epoch 88/150\n",
      "614/614 [==============================] - 0s 125us/step - loss: 0.2050 - acc: 0.6743 0s - loss: 0.2053 - acc: 0.673\n",
      "Epoch 89/150\n",
      "614/614 [==============================] - 0s 135us/step - loss: 0.2063 - acc: 0.6710\n",
      "Epoch 90/150\n",
      "614/614 [==============================] - 0s 138us/step - loss: 0.2110 - acc: 0.6661\n",
      "Epoch 91/150\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.2087 - acc: 0.6661\n",
      "Epoch 92/150\n",
      "614/614 [==============================] - 0s 138us/step - loss: 0.2070 - acc: 0.6694\n",
      "Epoch 93/150\n",
      "614/614 [==============================] - 0s 130us/step - loss: 0.2074 - acc: 0.6629\n",
      "Epoch 94/150\n",
      "614/614 [==============================] - 0s 127us/step - loss: 0.2072 - acc: 0.6661\n",
      "Epoch 95/150\n",
      "614/614 [==============================] - 0s 127us/step - loss: 0.2052 - acc: 0.6678\n",
      "Epoch 96/150\n",
      "614/614 [==============================] - 0s 127us/step - loss: 0.2075 - acc: 0.6612\n",
      "Epoch 97/150\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.2039 - acc: 0.6775\n",
      "Epoch 98/150\n",
      "614/614 [==============================] - 0s 127us/step - loss: 0.2045 - acc: 0.6678\n",
      "Epoch 99/150\n",
      "614/614 [==============================] - 0s 145us/step - loss: 0.2051 - acc: 0.6645\n",
      "Epoch 100/150\n",
      "614/614 [==============================] - 0s 156us/step - loss: 0.2085 - acc: 0.6694\n",
      "Epoch 101/150\n",
      "614/614 [==============================] - 0s 145us/step - loss: 0.2067 - acc: 0.6645\n",
      "Epoch 102/150\n",
      "614/614 [==============================] - 0s 227us/step - loss: 0.2036 - acc: 0.6759\n",
      "Epoch 103/150\n",
      "614/614 [==============================] - 0s 249us/step - loss: 0.2103 - acc: 0.6792\n",
      "Epoch 104/150\n",
      "614/614 [==============================] - 0s 200us/step - loss: 0.2061 - acc: 0.6759\n",
      "Epoch 105/150\n",
      "614/614 [==============================] - 0s 185us/step - loss: 0.2104 - acc: 0.6547\n",
      "Epoch 106/150\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.2056 - acc: 0.6873\n",
      "Epoch 107/150\n",
      "614/614 [==============================] - 0s 135us/step - loss: 0.2054 - acc: 0.6710\n",
      "Epoch 108/150\n",
      "614/614 [==============================] - 0s 110us/step - loss: 0.2041 - acc: 0.6889\n",
      "Epoch 109/150\n",
      "614/614 [==============================] - 0s 110us/step - loss: 0.2111 - acc: 0.6596\n",
      "Epoch 110/150\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.2080 - acc: 0.6433\n",
      "Epoch 111/150\n",
      "614/614 [==============================] - 0s 107us/step - loss: 0.2043 - acc: 0.6710\n",
      "Epoch 112/150\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.2075 - acc: 0.6694\n",
      "Epoch 113/150\n",
      "614/614 [==============================] - 0s 161us/step - loss: 0.2049 - acc: 0.6612\n",
      "Epoch 114/150\n",
      "614/614 [==============================] - 0s 185us/step - loss: 0.2064 - acc: 0.6694\n",
      "Epoch 115/150\n",
      "614/614 [==============================] - 0s 205us/step - loss: 0.2050 - acc: 0.6694\n",
      "Epoch 116/150\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.2085 - acc: 0.6564\n",
      "Epoch 117/150\n",
      "614/614 [==============================] - 0s 162us/step - loss: 0.2089 - acc: 0.6775\n",
      "Epoch 118/150\n",
      "614/614 [==============================] - 0s 148us/step - loss: 0.2051 - acc: 0.6759\n",
      "Epoch 119/150\n",
      "614/614 [==============================] - 0s 167us/step - loss: 0.2050 - acc: 0.6678\n",
      "Epoch 120/150\n",
      "614/614 [==============================] - 0s 136us/step - loss: 0.2019 - acc: 0.6775\n",
      "Epoch 121/150\n",
      "614/614 [==============================] - 0s 223us/step - loss: 0.2048 - acc: 0.6645\n",
      "Epoch 122/150\n",
      "614/614 [==============================] - 0s 184us/step - loss: 0.2076 - acc: 0.6547\n",
      "Epoch 123/150\n",
      "614/614 [==============================] - 0s 159us/step - loss: 0.2020 - acc: 0.6889\n",
      "Epoch 124/150\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.2055 - acc: 0.6694\n",
      "Epoch 125/150\n",
      "614/614 [==============================] - 0s 107us/step - loss: 0.2095 - acc: 0.6612\n",
      "Epoch 126/150\n",
      "614/614 [==============================] - 0s 130us/step - loss: 0.2039 - acc: 0.6808\n",
      "Epoch 127/150\n",
      "614/614 [==============================] - 0s 153us/step - loss: 0.2046 - acc: 0.6694\n",
      "Epoch 128/150\n",
      "614/614 [==============================] - 0s 211us/step - loss: 0.2083 - acc: 0.6612\n",
      "Epoch 129/150\n",
      "614/614 [==============================] - 0s 218us/step - loss: 0.2037 - acc: 0.6987\n",
      "Epoch 130/150\n",
      "614/614 [==============================] - 0s 198us/step - loss: 0.2052 - acc: 0.6743\n",
      "Epoch 131/150\n",
      "614/614 [==============================] - 0s 132us/step - loss: 0.2004 - acc: 0.6889\n",
      "Epoch 132/150\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.2020 - acc: 0.6873\n",
      "Epoch 133/150\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.2050 - acc: 0.6645\n",
      "Epoch 134/150\n",
      "614/614 [==============================] - 0s 125us/step - loss: 0.2066 - acc: 0.6726\n",
      "Epoch 135/150\n",
      "614/614 [==============================] - 0s 112us/step - loss: 0.2032 - acc: 0.6726\n",
      "Epoch 136/150\n",
      "614/614 [==============================] - 0s 110us/step - loss: 0.2049 - acc: 0.6873\n",
      "Epoch 137/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2033 - acc: 0.6808\n",
      "Epoch 138/150\n",
      "614/614 [==============================] - 0s 122us/step - loss: 0.2054 - acc: 0.6759\n",
      "Epoch 139/150\n",
      "614/614 [==============================] - 0s 122us/step - loss: 0.2015 - acc: 0.6775\n",
      "Epoch 140/150\n",
      "614/614 [==============================] - 0s 123us/step - loss: 0.2029 - acc: 0.6840\n",
      "Epoch 141/150\n",
      "614/614 [==============================] - 0s 123us/step - loss: 0.2027 - acc: 0.6710\n",
      "Epoch 142/150\n",
      "614/614 [==============================] - 0s 125us/step - loss: 0.2031 - acc: 0.6938\n",
      "Epoch 143/150\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.2025 - acc: 0.6629\n",
      "Epoch 144/150\n",
      "614/614 [==============================] - 0s 114us/step - loss: 0.2045 - acc: 0.6645\n",
      "Epoch 145/150\n",
      "614/614 [==============================] - 0s 117us/step - loss: 0.2058 - acc: 0.6808\n",
      "Epoch 146/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2034 - acc: 0.6873\n",
      "Epoch 147/150\n",
      "614/614 [==============================] - 0s 115us/step - loss: 0.2023 - acc: 0.6580\n",
      "Epoch 148/150\n",
      "614/614 [==============================] - 0s 106us/step - loss: 0.2084 - acc: 0.6531\n",
      "Epoch 149/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.2062 - acc: 0.6726\n",
      "Epoch 150/150\n",
      "614/614 [==============================] - 0s 104us/step - loss: 0.2004 - acc: 0.6710\n",
      "154/154 [==============================] - 0s 622us/step\n",
      "\n",
      "acc: 64.29%\n"
     ]
    }
   ],
   "source": [
    "#Function definitions for piecewise linear activation function(n = 4)\n",
    "def f1(x) : \n",
    "    return 0 * x + 1\n",
    "\n",
    "def f2(x) : \n",
    "    return 0 * x\n",
    "\n",
    "def LF4_F(x) : \n",
    "    return 0.8 * x + 0.5\n",
    "    \n",
    "def linearFun4(x):\n",
    "    \n",
    "    return k.switch(x< -6, f2(x),\n",
    "                        k.switch(x< 0, LF4_F(x),\n",
    "                                     k.switch(x<6, LF4_F(x),f1(x))))\n",
    "\n",
    "#Neural network model using  piecewise linear activation function n = 4\n",
    "model1.add(Dense(8, input_dim=8, activation = linearFun4))\n",
    "model1.add(Dense(16,activation = linearFun4))\n",
    "model1.add(Dense(1, activation = linearFun4))\n",
    "\n",
    "model1.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model1.fit(X_train, Y_train, epochs=150, batch_size=10)\n",
    "\n",
    "#Evaluate the model\n",
    "scores1 = model1.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model1.metrics_names[1], scores1[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "614/614 [==============================] - 1s 1ms/step - loss: 0.2533 - acc: 0.4707\n",
      "Epoch 2/150\n",
      "614/614 [==============================] - 0s 164us/step - loss: 0.2410 - acc: 0.6368\n",
      "Epoch 3/150\n",
      "614/614 [==============================] - 0s 193us/step - loss: 0.2351 - acc: 0.6368\n",
      "Epoch 4/150\n",
      "614/614 [==============================] - 0s 213us/step - loss: 0.2322 - acc: 0.6368\n",
      "Epoch 5/150\n",
      "614/614 [==============================] - 0s 203us/step - loss: 0.2306 - acc: 0.6368\n",
      "Epoch 6/150\n",
      "614/614 [==============================] - 0s 179us/step - loss: 0.2297 - acc: 0.6368\n",
      "Epoch 7/150\n",
      "614/614 [==============================] - 0s 276us/step - loss: 0.2292 - acc: 0.6368\n",
      "Epoch 8/150\n",
      "614/614 [==============================] - 0s 180us/step - loss: 0.2287 - acc: 0.6368\n",
      "Epoch 9/150\n",
      "614/614 [==============================] - 0s 156us/step - loss: 0.2284 - acc: 0.6368\n",
      "Epoch 10/150\n",
      "614/614 [==============================] - 0s 149us/step - loss: 0.2282 - acc: 0.6368\n",
      "Epoch 11/150\n",
      "614/614 [==============================] - 0s 158us/step - loss: 0.2280 - acc: 0.6368\n",
      "Epoch 12/150\n",
      "614/614 [==============================] - 0s 154us/step - loss: 0.2277 - acc: 0.6368\n",
      "Epoch 13/150\n",
      "614/614 [==============================] - 0s 145us/step - loss: 0.2275 - acc: 0.6368\n",
      "Epoch 14/150\n",
      "614/614 [==============================] - 0s 151us/step - loss: 0.2271 - acc: 0.6368\n",
      "Epoch 15/150\n",
      "614/614 [==============================] - 0s 149us/step - loss: 0.2268 - acc: 0.6368\n",
      "Epoch 16/150\n",
      "614/614 [==============================] - 0s 146us/step - loss: 0.2265 - acc: 0.6368\n",
      "Epoch 17/150\n",
      "614/614 [==============================] - 0s 138us/step - loss: 0.2261 - acc: 0.6368\n",
      "Epoch 18/150\n",
      "614/614 [==============================] - 0s 133us/step - loss: 0.2257 - acc: 0.6368\n",
      "Epoch 19/150\n",
      "614/614 [==============================] - 0s 148us/step - loss: 0.2252 - acc: 0.6368\n",
      "Epoch 20/150\n",
      "614/614 [==============================] - 0s 138us/step - loss: 0.2249 - acc: 0.6368\n",
      "Epoch 21/150\n",
      "614/614 [==============================] - 0s 166us/step - loss: 0.2247 - acc: 0.6368\n",
      "Epoch 22/150\n",
      "614/614 [==============================] - 0s 197us/step - loss: 0.2242 - acc: 0.6368\n",
      "Epoch 23/150\n",
      "614/614 [==============================] - 0s 172us/step - loss: 0.2238 - acc: 0.6368\n",
      "Epoch 24/150\n",
      "614/614 [==============================] - 0s 149us/step - loss: 0.2233 - acc: 0.6368\n",
      "Epoch 25/150\n",
      "614/614 [==============================] - 0s 151us/step - loss: 0.2229 - acc: 0.6368\n",
      "Epoch 26/150\n",
      "614/614 [==============================] - 0s 130us/step - loss: 0.2225 - acc: 0.6368\n",
      "Epoch 27/150\n",
      "614/614 [==============================] - 0s 128us/step - loss: 0.2219 - acc: 0.6368\n",
      "Epoch 28/150\n",
      "614/614 [==============================] - 0s 132us/step - loss: 0.2215 - acc: 0.6368\n",
      "Epoch 29/150\n",
      "614/614 [==============================] - 0s 135us/step - loss: 0.2212 - acc: 0.6368\n",
      "Epoch 30/150\n",
      "614/614 [==============================] - 0s 136us/step - loss: 0.2207 - acc: 0.6368\n",
      "Epoch 31/150\n",
      "614/614 [==============================] - 0s 138us/step - loss: 0.2203 - acc: 0.6368\n",
      "Epoch 32/150\n",
      " 10/614 [..............................] - ETA: 0s - loss: 0.2210 - acc: 0.6000"
     ]
    }
   ],
   "source": [
    "#Function definitions for piecewise linear activation function(n = 6)\n",
    "def LF6_F1(x) : \n",
    "    return 0.06 * x + 0.4\n",
    "\n",
    "def LF6_F2(x) : \n",
    "    return 0.1 * x + 0.5\n",
    "\n",
    "def LF6_F3(x) : \n",
    "    return 0.1333 * x + 0.5\n",
    "\n",
    "def LF6_F4(x) : \n",
    "    return 0.0333 * x + 0.8\n",
    " \n",
    "def linearFun6(x):\n",
    "    \n",
    "    return k.switch(x< -6, f2(x),\n",
    "                   k.switch(x< -3, LF6_F1(x),\n",
    "                            k.switch(x< 0, LF6_F2(x),\n",
    "                                k.switch(x< 3, LF6_F3(x),                                     \n",
    "                                   k.switch(x<6, LF6_F4(x),f1(x))))))\n",
    "\n",
    "#Neural network model using  piecewise linear activation function n = 6\n",
    "model2.add(Dense(8, input_dim=8, activation = linearFun6))\n",
    "model2.add(Dense(16,activation = linearFun6))\n",
    "model2.add(Dense(1, activation = linearFun6))\n",
    "\n",
    "model2.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model2.fit(X_train, Y_train, epochs=150, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores2 = model2.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model2.metrics_names[1], scores2[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function definitions for piecewise linear activation function(n = 8)\n",
    "def LF8_F1(x) : \n",
    "    return 0.05 * x + 0.3\n",
    "\n",
    "def LF8_F2(x) : \n",
    "    return 0.133 * x + 0.6333\n",
    "\n",
    "def LF8_F3(x) : \n",
    "    return 0.08 * x + 0.38\n",
    "\n",
    "def LF8_F4(x) : \n",
    "    return 0.1 * x + 0.57\n",
    "\n",
    "def LF8_F5(x) : \n",
    "    return 0.133 * x + 0.3\n",
    "\n",
    "def LF8_F6(x) : \n",
    "    return 0.05 * x + 0.73\n",
    " \n",
    "def linearFun8(x):\n",
    "    \n",
    "    return k.switch(x< -6, f2(x),\n",
    "                   k.switch(x< -4, LF8_F1(x),\n",
    "                        k.switch(x< -2, LF8_F2(x),\n",
    "                            k.switch(x< 0, LF8_F3(x),\n",
    "                                k.switch(x< 2, LF8_F4(x),\n",
    "                                    k.switch(x< 4, LF8_F5(x),                                   \n",
    "                                           k.switch(x<6, LF8_F6(x),f1(x))))))))\n",
    "\n",
    "#Neural network model using  piecewise linear activation function n = 8\n",
    "model3.add(Dense(8, input_dim=8))\n",
    "model3.add(Dense(16,activation = linearFun8))\n",
    "model3.add(Dense(1))\n",
    "\n",
    "model3.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model3.fit(X_train, Y_train, epochs=150, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores3 = model3.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model3.metrics_names[1], scores3[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function definitions for piecewise linear activation function(n = 10)\n",
    "def LF10_F1(x) : \n",
    "    return 0.0667 * x + 0.4\n",
    "\n",
    "def LF10_F2(x) : \n",
    "    return 0.08 * x + 0.48\n",
    "\n",
    "def LF10_F3(x) : \n",
    "    return 0.1 * x + 0.5\n",
    "\n",
    "def LF10_F4(x) : \n",
    "    return 0.0067 * x + 0.5\n",
    "\n",
    "def LF10_F5(x) : \n",
    "    return 0.133 * x + 0.5\n",
    "\n",
    "def LF10_F6(x) : \n",
    "    return 0.0667 * x + 0.6\n",
    "\n",
    "def LF10_F7(x) : \n",
    "    return 0.0533 * x + 0.67\n",
    "\n",
    "def LF10_F8(x) : \n",
    "    return 0.08 * x + 0.52\n",
    " \n",
    "def linearFun10(x):\n",
    "    \n",
    "    return k.switch(x< -6, f2(x),\n",
    "                   k.switch(x< -4.5, LF10_F1(x),\n",
    "                        k.switch(x< -3, LF10_F2(x),\n",
    "                            k.switch(x< -1.5, LF10_F3(x),\n",
    "                                k.switch(x< 0, LF10_F4(x),\n",
    "                                    k.switch(x< 1.5, LF10_F5(x),  \n",
    "                                             k.switch(x< 3, LF10_F6(x),\n",
    "                                                k.switch(x< 4.5, LF10_F7(x),\n",
    "                                                   k.switch(x<6, LF10_F8(x),f1(x))))))))))\n",
    "\n",
    "#model using  piecewise linear activation function n = 10\n",
    "model4.add(Dense(8, input_dim=8))\n",
    "model4.add(Dense(16,activation = linearFun10))\n",
    "model4.add(Dense(1))\n",
    "\n",
    "model4.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model4.fit(X_train, Y_train, epochs=150, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores4 = model4.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model4.metrics_names[1], scores4[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function definitions for piecewise linear activation function(n = 12)\n",
    "def LF12_F1(x) : \n",
    "    return 0.075 * x + 0.43\n",
    "\n",
    "def LF12_F2(x) : \n",
    "    return 0.0667 * x + 0.42\n",
    "\n",
    "def LF12_F3(x) : \n",
    "    return 0.125 * x + 0.50\n",
    "\n",
    "def LF12_F4(x) : \n",
    "    return 0.075 * x + 0.67\n",
    "\n",
    "def LF12_F5(x) : \n",
    "    return 0.025 * x + 0.5\n",
    "\n",
    "def LF12_F6(x) : \n",
    "    return 0.0833 * x + 0.5\n",
    "\n",
    "def LF12_F7(x) : \n",
    "    return 0.075 * x + 0.51\n",
    "\n",
    "def LF12_F8(x) : \n",
    "    return 0.1333 * x + 0.34\n",
    "\n",
    "def LF12_F9(x) : \n",
    "    return 0.05833 * x + 0.64\n",
    "\n",
    "def LF12_F10(x) : \n",
    "    return 0.0667 * x + 0.6\n",
    " \n",
    "def linearFun12(x):\n",
    "    \n",
    "    return k.switch(x< -6, f2(x),\n",
    "                   k.switch(x< -4.8, LF12_F1(x),\n",
    "                        k.switch(x< -3.6, LF12_F2(x),\n",
    "                            k.switch(x< -2.4, LF12_F3(x),\n",
    "                                k.switch(x< -1.2, LF12_F4(x),\n",
    "                                    k.switch(x< 0, LF12_F5(x),  \n",
    "                                             k.switch(x< 1.2, LF12_F6(x),\n",
    "                                                k.switch(x< 2.4, LF12_F7(x),\n",
    "                                                    k.switch(x< 3.6, LF12_F8(x),\n",
    "                                                        k.switch(x< 4.8, LF12_F9(x),\n",
    "                                                           k.switch(x<6, LF12_F8(x),f1(x))))))))))))\n",
    "\n",
    "#model using  piecewise linear activation function n = 12\n",
    "model5.add(Dense(8, input_dim=8))\n",
    "model5.add(Dense(16,activation = linearFun12))\n",
    "model5.add(Dense(1))\n",
    "\n",
    "model5.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model5.fit(X_train, Y_train, epochs=150, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores5 = model5.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model5.metrics_names[1], scores5[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function definitions for piecewise linear activation function(n = 14)\n",
    "def LF14_F1(x) : \n",
    "    return 0.05 * x + 0.33\n",
    "\n",
    "def LF14_F2(x) : \n",
    "    return 0.07 * x + 0.41\n",
    "\n",
    "def LF14_F3(x) : \n",
    "    return 0.08 * x + 0.45\n",
    "\n",
    "def LF14_F4(x) : \n",
    "    return 0.17 * x + 0.71\n",
    "\n",
    "def LF14_F5(x) : \n",
    "    return 0.11 * x + 0.59\n",
    "\n",
    "def LF14_F6(x) : \n",
    "    return 0.02 * x + 0.5\n",
    "\n",
    "def LF14_F7(x) : \n",
    "    return 0.06 * x + 0.51\n",
    "\n",
    "def LF14_F8(x) : \n",
    "    return 0.07 * x + 0.34\n",
    "\n",
    "def LF14_F9(x) : \n",
    "    return 0.18 * x + 0.27\n",
    "\n",
    "def LF14_F10(x) : \n",
    "    return 0.08 * x + 0.57\n",
    "\n",
    "def LF14_F11(x) : \n",
    "    return 0.05 * x + 0.69\n",
    "\n",
    "def LF14_F12(x) : \n",
    "    return 0.06 * x + 0.64\n",
    "\n",
    "def linearFun14(x):\n",
    "    \n",
    "    return k.switch(x< -6, f2(x),\n",
    "                   k.switch(x< -5, LF14_F1(x),\n",
    "                        k.switch(x< -4, LF14_F2(x),\n",
    "                            k.switch(x< -3, LF14_F3(x),\n",
    "                                k.switch(x< -2, LF14_F4(x),\n",
    "                                    k.switch(x< -1, LF14_F5(x),  \n",
    "                                             k.switch(x< 0, LF14_F6(x),\n",
    "                                                k.switch(x< 1, LF14_F7(x),\n",
    "                                                    k.switch(x< 2, LF14_F8(x),\n",
    "                                                        k.switch(x< 3, LF14_F9(x),\n",
    "                                                            k.switch(x< 4, LF14_F10(x),\n",
    "                                                                k.switch(x< 5, LF14_F11(x),\n",
    "                                                                   k.switch(x<6, LF14_F12(x),f1(x))))))))))))))\n",
    "\n",
    "#model using  piecewise linear activation function n = 14\n",
    "model6.add(Dense(8, input_dim=8))\n",
    "model6.add(Dense(16,activation = linearFun14))\n",
    "model6.add(Dense(1))\n",
    "\n",
    "model6.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model6.fit(X_train, Y_train, epochs=150, batch_size=10)\n",
    "\n",
    "# evaluate the model\n",
    "scores6 = model6.evaluate(X_test, Y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model6.metrics_names[1], scores6[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

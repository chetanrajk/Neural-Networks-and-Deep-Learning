{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.reshape(614,1)\n",
    "Y_test = Y_test.reshape(154,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Neural Network with normal backpropagation implementation\n",
    "\n",
    "class NeuralNetwork(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input = X_train.shape[1]\n",
    "        self.learning = 0.04\n",
    "        self.hidden = (X_train.shape[1]*2)\n",
    "        self.output = 1\n",
    "    \n",
    "        self.W1 = np.random.randn(self.input, self.hidden)\n",
    "        self.W2 = np.random.randn(self.hidden, self.output)\n",
    "    \n",
    "    def sigmoid(self,x):\n",
    "        return 1.0/(1+ np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self,x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def feedforward(self,X):\n",
    "        self.z = np.dot(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = np.dot(self.z2, self.W2)\n",
    "        O = self.sigmoid(self.z3)\n",
    "        return O\n",
    "    \n",
    "    def backpropgation(self,X, Y, O):\n",
    "        self.o_error = Y - O\n",
    "        self.o_delta = self.o_error*self.sigmoid_derivative(O)\n",
    "\n",
    "        self.z2_error = self.o_delta.dot(self.W2.T) \n",
    "        self.z2_delta = self.z2_error*self.sigmoid_derivative(self.z2)\n",
    "\n",
    "        self.W1 += self.learning*X.T.dot(self.z2_delta)\n",
    "        self.W2 += self.learning*self.z2.T.dot(self.o_delta)\n",
    "        \n",
    "    def trainNN (self, X, Y):\n",
    "        O = self.feedforward(X)\n",
    "        self.backpropgation(X, Y, O)\n",
    "        \n",
    "    def accuracy(self,X):\n",
    "        self.z = np.dot(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z) \n",
    "        self.z3 = np.dot(self.z2, self.W2)\n",
    "        O = self.sigmoid(self.z3) \n",
    "        return O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train first neural network\n",
    "\n",
    "NN = NeuralNetwork()\n",
    "\n",
    "for i in range(250):\n",
    "    print (\"Loss: \\n\" + str(np.mean(np.square(Y_train- NN.feedforward(X_train)))))\n",
    "    NN.trainNN(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second neural network with modified backpropagation\n",
    "\n",
    "class NeuralNetwork2(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input = X_train.shape[1]\n",
    "        self.learning = 0.04\n",
    "        self.hidden = (X_train.shape[1]*2)\n",
    "        self.output = 1\n",
    "    \n",
    "        self.W1 = np.random.randn(self.input, self.hidden)\n",
    "        self.W2 = np.random.randn(self.hidden, self.output)\n",
    "\n",
    "    def feedforward(self,X):\n",
    "        self.z = np.dot(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = np.dot(self.z2, self.W2)\n",
    "        O = self.sigmoid(self.z3)\n",
    "        return O\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return 1.0/(1+ np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sigmoid_derivative(self,x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    \n",
    "    def backpropgation(self,X, Y, O):\n",
    "\n",
    "        for fl in O > 0.5:\n",
    "            if fl:\n",
    "                self.o_error = 1-O\n",
    "            else:\n",
    "                self.o_error = Y-O\n",
    "                \n",
    "        self.o_delta = self.o_error*self.sigmoid_derivative(O)\n",
    "\n",
    "        self.z2_error = self.o_delta.dot(self.W2.T) \n",
    "        self.z2_delta = self.z2_error*self.sigmoid_derivative(self.z2)\n",
    "\n",
    "        self.W1 += self.learning*X.T.dot(self.z2_delta) \n",
    "        self.W2 += self.learning*self.z2.T.dot(self.o_delta) \n",
    "    \n",
    "    def train (self, X, Y):\n",
    "        O = self.feedforward(X)\n",
    "        self.backpropgation(X, Y, O)\n",
    "        \n",
    "    def accuracy(self,X):\n",
    "        self.z = np.dot(X, self.W1) \n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = np.dot(self.z2, self.W2) \n",
    "        O = self.sigmoid(self.z3) \n",
    "        return O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train second neural network\n",
    "\n",
    "NN2 = NeuralNetwork2()\n",
    "for i in range(250): \n",
    "    print (\"Loss: \\n\" + str(np.mean(np.square(Y_train- NN2.feedforward(X_train)))))\n",
    "    print (\"\\n\")\n",
    "    NN2.train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Neural Network with normal backpropagation \n",
    "\n",
    "NN = NeuralNetwork()\n",
    "y_pred1  = NN.accuracy(X_test)\n",
    "y_pred1 = [round(x[0]) for x in y_pred1 ]\n",
    "\n",
    "cm = confusion_matrix(Y_test,y_pred1)\n",
    "FPR = cm[0,1]/(cm[0,1] + cm[0,0])\n",
    "FNR = cm[1,0]/(cm[1,0] + cm[1,1])\n",
    "\n",
    "print(\"Output with normal implementation of backpropagation:\")\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nFalse Positive Rate (FPR) :- %.2f%%\" % (FPR * 100))\n",
    "print(\"False Negative Rate (FNR) :- %.2f%%\" % (FNR * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second Neural Network with updated backpropagation \n",
    "\n",
    "NN2 = NeuralNetwork2()\n",
    "y_pred2  = NN2.accuracy(X_test)\n",
    "y_pred2 = [round(x[0]) for x in y_pred2 ]\n",
    "\n",
    "cm1 = confusion_matrix(Y_test,y_pred2)\n",
    "FPR = cm1[0,1]/(cm1[0,1] + cm1[0,0])\n",
    "FNR = cm1[1,0]/(cm1[1,0] + cm1[1,1])\n",
    "\n",
    "print(\"Output after modification of backpropagation:\")\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(cm1)\n",
    "\n",
    "print(\"\\nFalse Positive Rate (FPR) :- %.2f%%\" % (FPR * 100))\n",
    "print(\"False Negative Rate (FNR) :- %.2f%%\" % (FNR * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
